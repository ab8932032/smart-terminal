model_providers:
  ollama:
    adapter: adapters.model.ollama_adapter.OllamaAdapter
    endpoint: "http://localhost:11434"
    generation_params: # 新增生成参数
      max_concurrent_tasks: 3
      timeout: 30
    model_name: "deepseek-r1:7b"
    temperature: 0.8
    top_p: 0.95
    max_tokens: 4096
    enabled: false
    
  huggingface:
    adapter: adapters.model.hf_pipeline.HuggingFacePipeline
    model_name: "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B"
    quantization:
      enabled: true
      type: "nf4"
    model_args:
      attn_implementation: "flash_attention_2"
    generation:
      max_new_tokens: 8192
      temperature: 0.7
      search_top_k: 5
    generation_params: # 新增生成参数
      max_concurrent_tasks: 3
      timeout: 30
    enabled: true
      
logging:
  path: "logs/chat_histories"
  level: "INFO"

session:
  storage_path: "./sessions"  # 会话存储目录
  auto_save_interval: 5       # 自动保存间隔


frontend_providers:
  tkinter:
    adapter: adapters.frontends.tkinter_gui.TkinterFrontend
    enabled: true
  web:
    adapter: adapters.frontends.web_frontend.WebFrontend
    enabled: false
    host: "127.0.0.1"
    port: 8000
    cors_allowed_origins: [ "http://localhost:3000" ]